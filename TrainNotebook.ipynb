{"cells":[{"cell_type":"markdown","metadata":{},"source":["------ Installazione delle dipendenze ------"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-01-16T21:07:06.094125Z","iopub.status.busy":"2024-01-16T21:07:06.093637Z","iopub.status.idle":"2024-01-16T21:07:37.966118Z","shell.execute_reply":"2024-01-16T21:07:37.964664Z","shell.execute_reply.started":"2024-01-16T21:07:06.094088Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing /kaggle/input/cocohelper/cocohelper-0.3.4-py3-none-any.whl\n","Requirement already satisfied: numpy<2.0.0,>=1.23.4 in /opt/conda/lib/python3.10/site-packages (from cocohelper==0.3.4) (1.24.3)\n","Requirement already satisfied: opencv-python<5.0.0.0,>=4.6.0.66 in /opt/conda/lib/python3.10/site-packages (from cocohelper==0.3.4) (4.8.1.78)\n","Collecting pandas<2.0.0,>=1.5.1 (from cocohelper==0.3.4)\n","  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting pillow<10.0.0,>=9.3.0 (from cocohelper==0.3.4)\n","  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hCollecting pycocotools<3.0.0,>=2.0.6 (from cocohelper==0.3.4)\n","  Obtaining dependency information for pycocotools<3.0.0,>=2.0.6 from https://files.pythonhosted.org/packages/ba/64/0451cf41a00fd5ac4501de4ea0e395b7d909e09d665e56890b5d3809ae26/pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n","Requirement already satisfied: scikit-learn<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from cocohelper==0.3.4) (1.2.2)\n","Requirement already satisfied: shapely<1.9.0,>=1.8.2 in /opt/conda/lib/python3.10/site-packages (from cocohelper==0.3.4) (1.8.5.post1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from cocohelper==0.3.4) (4.66.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0,>=1.5.1->cocohelper==0.3.4) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0,>=1.5.1->cocohelper==0.3.4) (2023.3)\n","Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools<3.0.0,>=2.0.6->cocohelper==0.3.4) (3.7.3)\n","Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.1.3->cocohelper==0.3.4) (1.11.3)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.1.3->cocohelper==0.3.4) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.1.3->cocohelper==0.3.4) (3.2.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools<3.0.0,>=2.0.6->cocohelper==0.3.4) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools<3.0.0,>=2.0.6->cocohelper==0.3.4) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools<3.0.0,>=2.0.6->cocohelper==0.3.4) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools<3.0.0,>=2.0.6->cocohelper==0.3.4) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools<3.0.0,>=2.0.6->cocohelper==0.3.4) (21.3)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools<3.0.0,>=2.0.6->cocohelper==0.3.4) (3.0.9)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.5.1->cocohelper==0.3.4) (1.16.0)\n","Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pillow, pandas, pycocotools, cocohelper\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 10.1.0\n","    Uninstalling Pillow-10.1.0:\n","      Successfully uninstalled Pillow-10.1.0\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.0.3\n","    Uninstalling pandas-2.0.3:\n","      Successfully uninstalled pandas-2.0.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","beatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.10.0 which is incompatible.\n","beatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\n","fitter 1.6.0 requires pandas<3.0.0,>=2.0.3, but you have pandas 1.5.3 which is incompatible.\n","libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","momepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\n","pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\n","tensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\n","ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cocohelper-0.3.4 pandas-1.5.3 pillow-9.5.0 pycocotools-2.0.7\n","\u001b[31mERROR: pycocotools-2.0-cp37-cp37m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install  /kaggle/input/cocohelper/cocohelper-0.3.4-py3-none-any.whl\n","!pip install /kaggle/input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:47:20.004369Z","iopub.status.busy":"2024-01-14T22:47:20.003632Z","iopub.status.idle":"2024-01-14T22:47:32.988188Z","shell.execute_reply":"2024-01-14T22:47:32.987127Z","shell.execute_reply.started":"2024-01-14T22:47:20.004321Z"},"trusted":true},"outputs":[],"source":["!pip install gitpython\n","# cartella per ospitare il codice della repo\n","!mkdir code\n","# cartella in cui verranno salvati i pesi dopo l'addestramento\n","!mkdir checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:47:32.990122Z","iopub.status.busy":"2024-01-14T22:47:32.989739Z","iopub.status.idle":"2024-01-14T22:47:34.707708Z","shell.execute_reply":"2024-01-14T22:47:34.706753Z","shell.execute_reply.started":"2024-01-14T22:47:32.990083Z"},"trusted":true},"outputs":[],"source":["import git\n","import sys\n","\n","git.Repo.clone_from('https://github.com/IDEA-Research/MaskDINO', '/kaggle/working/code')\n","sys.path.append('kaggle/working/code')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-01-14T22:47:34.710255Z","iopub.status.busy":"2024-01-14T22:47:34.709956Z","iopub.status.idle":"2024-01-14T22:50:22.050385Z","shell.execute_reply":"2024-01-14T22:50:22.049399Z","shell.execute_reply.started":"2024-01-14T22:47:34.710229Z"},"trusted":true},"outputs":[],"source":["!python -m pip install -U setuptools pip\n","!pip install cupy-cuda12x\n","!pip install -r code/requirements.txt\n","!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-01-14T22:50:22.052331Z","iopub.status.busy":"2024-01-14T22:50:22.051956Z","iopub.status.idle":"2024-01-14T22:50:55.833717Z","shell.execute_reply":"2024-01-14T22:50:55.832567Z","shell.execute_reply.started":"2024-01-14T22:50:22.052290Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!cd code/maskdino/modeling/pixel_decoder/ops && sh make.sh"]},{"cell_type":"markdown","metadata":{},"source":["---Modifica del file di configurazione del modello----"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:50:55.836138Z","iopub.status.busy":"2024-01-14T22:50:55.835376Z","iopub.status.idle":"2024-01-14T22:50:55.842753Z","shell.execute_reply":"2024-01-14T22:50:55.841694Z","shell.execute_reply.started":"2024-01-14T22:50:55.836093Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","# Imposta una variabile di ambiente chiamata 'NOME_VARIAILE' con il valore 'VALORE_VARIAILE'\n","os.environ['DETECTRON2_DATASETS'] = \"/kaggle/input/ttpla-project-dataset/ttpla\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:52:41.568643Z","iopub.status.busy":"2024-01-14T22:52:41.568187Z","iopub.status.idle":"2024-01-14T22:52:41.599922Z","shell.execute_reply":"2024-01-14T22:52:41.598995Z","shell.execute_reply.started":"2024-01-14T22:52:41.568607Z"},"trusted":true},"outputs":[],"source":["import yaml\n","\n","# Carica il file YAML\n","with open(\"/kaggle/working/code/configs/coco/instance-segmentation/maskdino_R50_bs16_50ep_4s_dowsample1_2048.yaml\", 'r') as file:\n","    data = yaml.safe_load(file)\n","\n","# aggiungere qua i parametri per l'addestramento\n","if 'DATASETS' not in data:\n","    data['DATASETS'] = {}  \n","    \n","data['DATASETS']['TRAIN'] = '(\"ttpla_train\",)'\n","data['DATASETS']['TEST'] = '(\"ttpla_test\",)'\n","data['SOLVER']['MAX_ITER'] = 1\n","data['SOLVER']['OPTIMIZER'] = \"ADAMW\"\n","data['SOLVER']['IMS_PER_BATCH'] = 2\n","data['SOLVER']['BASE_LR'] = 0.00001\n","data['MODEL']['SEM_SEG_HEAD']['NUM_CLASSES'] = 5\n","data['TEST']['EVAL_PERIOD'] = 1\n","\n","if 'INPUT' not in data:\n","    data['INPUT']={}\n","\n","data['INPUT']['MAX_SCALE']=2.0\n","data['INPUT']['IMAGE_SIZE']=700\n","\n","if 'OUTPUT_DIR' not in data:\n","    data['OUTPUT_DIR'] = {} \n","    \n","data['OUTPUT_DIR'] = \"/kaggle/working/checkpoint\"\n","\n","# AGGIUNGERE ALTRI PARAMETRI ? Cambiare num di classi e vedere model weights se e' corretto\n","\n","os.makedirs(data['OUTPUT_DIR'], exist_ok=True)\n","\n","# Salvataggio del file sovrascrivendo l'origiunale\n","with open(\"/kaggle/working/code/configs/coco/instance-segmentation/maskdino_R50_bs16_50ep_4s_dowsample1_2048.yaml\", 'w') as file:\n","    yaml.dump(data, file)"]},{"cell_type":"markdown","metadata":{},"source":["---modifica dello script coco_instance_new_baseline_dataset_mapper.py per includere trasformazioni aggiuntive---"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:50:55.903843Z","iopub.status.busy":"2024-01-14T22:50:55.903263Z","iopub.status.idle":"2024-01-14T22:50:55.916608Z","shell.execute_reply":"2024-01-14T22:50:55.915820Z","shell.execute_reply.started":"2024-01-14T22:50:55.903808Z"},"trusted":true},"outputs":[],"source":["file = open(\"/kaggle/working/code/maskdino/data/dataset_mappers/coco_instance_new_baseline_dataset_mapper.py\",mode=\"w\")\n","file.write('''# ------------------------------------------------------------------------\n","# Copyright (c) 2022 IDEA. All Rights Reserved.\n","# Licensed under the Apache License, Version 2.0 [see LICENSE for details]\n","# ------------------------------------------------------------------------\n","# Modified from Mask2Former https://github.com/facebookresearch/Mask2Former by Feng Li.\n","import copy\n","import logging\n","\n","import numpy as np\n","import torch\n","\n","from detectron2.config import configurable\n","from detectron2.data import detection_utils as utils\n","from detectron2.data import transforms as T\n","from detectron2.data.transforms import TransformGen\n","from detectron2.structures import BitMasks, Instances, PolygonMasks\n","\n","from pycocotools import mask as coco_mask\n","\n","__all__ = [\"COCOInstanceNewBaselineDatasetMapper\"]\n","\n","\n","def convert_coco_poly_to_mask(segmentations, height, width):\n","    masks = []\n","    for polygons in segmentations:\n","        rles = coco_mask.frPyObjects(polygons, height, width)\n","        mask = coco_mask.decode(rles)\n","        if len(mask.shape) < 3:\n","            mask = mask[..., None]\n","        mask = torch.as_tensor(mask, dtype=torch.uint8)\n","        mask = mask.any(dim=2)\n","        masks.append(mask)\n","    if masks:\n","        masks = torch.stack(masks, dim=0)\n","    else:\n","        masks = torch.zeros((0, height, width), dtype=torch.uint8)\n","    return masks\n","\n","\n","def build_transform_gen(cfg, is_train):\n","    \"\"\"\n","    Create a list of default :class:`Augmentation` from config.\n","    Now it includes resizing and flipping.\n","    Returns:\n","        list[Augmentation]\n","    \"\"\"\n","    assert is_train, \"Only support training augmentation\"\n","    image_size = cfg.INPUT.IMAGE_SIZE\n","    min_scale = cfg.INPUT.MIN_SCALE\n","    max_scale = cfg.INPUT.MAX_SCALE\n","\n","    augmentation = []\n","    if cfg.INPUT.RANDOM_FLIP != \"none\":\n","        augmentation.append(\n","            T.RandomFlip(\n","                horizontal=cfg.INPUT.RANDOM_FLIP == \"horizontal\",\n","                vertical=cfg.INPUT.RANDOM_FLIP == \"vertical\",\n","            )\n","        )\n","    \n","    augmentation.extend([\n","        T.ResizeScale(\n","            min_scale=min_scale, max_scale=max_scale, target_height=image_size, target_width=image_size\n","        ),\n","        T.FixedSizeCrop(crop_size=(image_size, image_size)),\n","        T.RandomContrast(intensity_min=0.5, intensity_max=1.5),\n","        T.RandomSaturation(intensity_min=0.5, intensity_max=1.5),\n","    ])\n","\n","    return augmentation\n","\n","\n","class COCOInstanceNewBaselineDatasetMapper:\n","    \"\"\"\n","    A callable which takes a dataset dict in Detectron2 Dataset format,\n","    and map it into a format used by MaskFormer.\n","\n","    This dataset mapper applies the same transformation as DETR for COCO panoptic segmentation.\n","\n","    The callable currently does the following:\n","\n","    1. Read the image from \"file_name\"\n","    2. Applies geometric transforms to the image and annotation\n","    3. Find and applies suitable cropping to the image and annotation\n","    4. Prepare image and annotation to Tensors\n","    \"\"\"\n","\n","    @configurable\n","    def __init__(\n","        self,\n","        is_train=True,\n","        *,\n","        tfm_gens,\n","        image_format,\n","    ):\n","        \"\"\"\n","        NOTE: this interface is experimental.\n","        Args:\n","            is_train: for training or inference\n","            augmentations: a list of augmentations or deterministic transforms to apply\n","            tfm_gens: data augmentation\n","            image_format: an image format supported by :func:`detection_utils.read_image`.\n","        \"\"\"\n","        self.tfm_gens = tfm_gens\n","        logging.getLogger(__name__).info(\n","            \"[COCOInstanceNewBaselineDatasetMapper] Full TransformGens used in training: {}\".format(str(self.tfm_gens))\n","        )\n","\n","        self.img_format = image_format\n","        self.is_train = is_train\n","    \n","    @classmethod\n","    def from_config(cls, cfg, is_train=True):\n","        # Build augmentation\n","        tfm_gens = build_transform_gen(cfg, is_train)\n","\n","        ret = {\n","            \"is_train\": is_train,\n","            \"tfm_gens\": tfm_gens,\n","            \"image_format\": cfg.INPUT.FORMAT,\n","        }\n","        return ret\n","\n","    def __call__(self, dataset_dict):\n","        \"\"\"\n","        Args:\n","            dataset_dict (dict): Metadata of one image, in Detectron2 Dataset format.\n","\n","        Returns:\n","            dict: a format that builtin models in detectron2 accept\n","        \"\"\"\n","        dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n","        image = utils.read_image(dataset_dict[\"file_name\"], format=self.img_format)\n","        utils.check_image_size(dataset_dict, image)\n","\n","        # TODO: get padding mask\n","        # by feeding a \"segmentation mask\" to the same transforms\n","        padding_mask = np.ones(image.shape[:2])\n","\n","        image, transforms = T.apply_transform_gens(self.tfm_gens, image)\n","        # the crop transformation has default padding value 0 for segmentation\n","        padding_mask = transforms.apply_segmentation(padding_mask)\n","        padding_mask = ~ padding_mask.astype(bool)\n","\n","        image_shape = image.shape[:2]  # h, w\n","\n","        # Pytorch's dataloader is efficient on torch.Tensor due to shared-memory,\n","        # but not efficient on large generic data structures due to the use of pickle & mp.Queue.\n","        # Therefore it's important to use torch.Tensor.\n","        dataset_dict[\"image\"] = torch.as_tensor(np.ascontiguousarray(image.transpose(2, 0, 1)))\n","        dataset_dict[\"padding_mask\"] = torch.as_tensor(np.ascontiguousarray(padding_mask))\n","\n","        if not self.is_train:\n","            # USER: Modify this if you want to keep them for some reason.\n","            dataset_dict.pop(\"annotations\", None)\n","            return dataset_dict\n","\n","        if \"annotations\" in dataset_dict:\n","            # USER: Modify this if you want to keep them for some reason.\n","            for anno in dataset_dict[\"annotations\"]:\n","                # Let's always keep mask\n","                anno.pop(\"keypoints\", None)\n","\n","            # USER: Implement additional transformations if you have other types of data\n","            annos = [\n","                utils.transform_instance_annotations(obj, transforms, image_shape)\n","                for obj in dataset_dict.pop(\"annotations\")\n","                if obj.get(\"iscrowd\", 0) == 0\n","            ]\n","            # NOTE: does not support BitMask due to augmentation\n","            # Current BitMask cannot handle empty objects\n","            instances = utils.annotations_to_instances(annos, image_shape)\n","            # After transforms such as cropping are applied, the bounding box may no longer\n","            # tightly bound the object. As an example, imagine a triangle object\n","            # [(0,0), (2,0), (0,2)] cropped by a box [(1,0),(2,2)] (XYXY format). The tight\n","            # bounding box of the cropped triangle should be [(1,0),(2,1)], which is not equal to\n","            # the intersection of original bounding box and the cropping box.\n","            if not instances.has('gt_masks'):  # this is to avoid empty annotation\n","                instances.gt_masks = PolygonMasks([])\n","            instances.gt_boxes = instances.gt_masks.get_bounding_boxes()\n","            # Need to filter empty instances first (due to augmentation)\n","            instances = utils.filter_empty_instances(instances)\n","            # Generate masks from polygon\n","            h, w = instances.image_size\n","            if hasattr(instances, 'gt_masks'):\n","                gt_masks = instances.gt_masks\n","                gt_masks = convert_coco_poly_to_mask(gt_masks.polygons, h, w)\n","                instances.gt_masks = gt_masks\n","\n","            dataset_dict[\"instances\"] = instances\n","\n","        return dataset_dict''')\n","file.close()"]},{"cell_type":"markdown","metadata":{},"source":["-----Modifica dello script train_net.py in modo da includere la registrazione del datset-----"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:50:55.918279Z","iopub.status.busy":"2024-01-14T22:50:55.917993Z","iopub.status.idle":"2024-01-14T22:50:55.937914Z","shell.execute_reply":"2024-01-14T22:50:55.937132Z","shell.execute_reply.started":"2024-01-14T22:50:55.918231Z"},"trusted":true},"outputs":[],"source":["file = open(\"/kaggle/working/code/train_net.py\",mode=\"w\")\n","file.write('''# ------------------------------------------------------------------------\n","# Copyright (c) 2022 IDEA. All Rights Reserved.\n","# Licensed under the Apache License, Version 2.0 [see LICENSE for details]\n","# by Feng Li and Hao Zhang.\n","# ------------------------------------------------------------------------\n","\"\"\"\n","MaskDINO Training Script based on Mask2Former.\n","\"\"\"\n","try:\n","    from shapely.errors import ShapelyDeprecationWarning\n","    import warnings\n","    warnings.filterwarnings('ignore', category=ShapelyDeprecationWarning)\n","except:\n","    pass\n","\n","import copy\n","import itertools\n","import logging\n","import os\n","\n","from collections import OrderedDict\n","from typing import Any, Dict, List, Set\n","\n","import torch\n","\n","import detectron2.utils.comm as comm\n","from detectron2.checkpoint import DetectionCheckpointer\n","from detectron2.config import get_cfg\n","from detectron2.data import MetadataCatalog, build_detection_train_loader\n","from detectron2.data.datasets import register_coco_instances\n","from detectron2.data.datasets.coco import convert_to_coco_json\n","\n","from detectron2.evaluation import (\n","    CityscapesInstanceEvaluator,\n","    CityscapesSemSegEvaluator,\n","    COCOEvaluator,\n","    COCOPanopticEvaluator,\n","    DatasetEvaluators,\n","    LVISEvaluator,\n","    SemSegEvaluator,\n","    verify_results,\n",")\n","from detectron2.projects.deeplab import add_deeplab_config, build_lr_scheduler\n","from detectron2.solver.build import maybe_add_gradient_clipping\n","from detectron2.utils.logger import setup_logger\n","\n","# MaskDINO\n","from maskdino import (\n","    COCOInstanceNewBaselineDatasetMapper,\n","    COCOPanopticNewBaselineDatasetMapper,\n","    InstanceSegEvaluator,\n","    MaskFormerSemanticDatasetMapper,\n","    SemanticSegmentorWithTTA,\n","    add_maskdino_config,\n","    DetrDatasetMapper,\n",")\n","import random\n","from detectron2.engine import (\n","    DefaultTrainer,\n","    default_argument_parser,\n","    default_setup,\n","    hooks,\n","    launch,\n","    create_ddp_model,\n","    AMPTrainer,\n","    SimpleTrainer\n",")\n","import weakref\n","\n","\n","class Trainer(DefaultTrainer):\n","    \"\"\"\n","    Extension of the Trainer class adapted to MaskFormer.\n","    \"\"\"\n","    def __init__(self, cfg):\n","        super(DefaultTrainer, self).__init__()\n","        logger = logging.getLogger(\"detectron2\")\n","        if not logger.isEnabledFor(logging.INFO):  # setup_logger is not called for d2\n","            setup_logger()\n","        cfg = DefaultTrainer.auto_scale_workers(cfg, comm.get_world_size())\n","\n","        # Assume these objects must be constructed in this order.\n","        model = self.build_model(cfg)\n","        optimizer = self.build_optimizer(cfg, model)\n","        data_loader = self.build_train_loader(cfg)\n","\n","        model = create_ddp_model(model, broadcast_buffers=False)\n","        self._trainer = (AMPTrainer if cfg.SOLVER.AMP.ENABLED else SimpleTrainer)(\n","            model, data_loader, optimizer\n","        )\n","\n","        self.scheduler = self.build_lr_scheduler(cfg, optimizer)\n","\n","        # add model EMA\n","        kwargs = {\n","            'trainer': weakref.proxy(self),\n","        }\n","        # kwargs.update(model_ema.may_get_ema_checkpointer(cfg, model)) TODO: release ema training for large models\n","        self.checkpointer = DetectionCheckpointer(\n","            # Assume you want to save checkpoints together with logs/statistics\n","            model,\n","            cfg.OUTPUT_DIR,\n","            **kwargs,\n","        )\n","        self.start_iter = 0\n","        self.max_iter = cfg.SOLVER.MAX_ITER\n","        self.cfg = cfg\n","\n","        self.register_hooks(self.build_hooks())\n","        # TODO: release model conversion checkpointer from DINO to MaskDINO\n","        self.checkpointer = DetectionCheckpointer(\n","            # Assume you want to save checkpoints together with logs/statistics\n","            model,\n","            cfg.OUTPUT_DIR,\n","            **kwargs,\n","        )\n","        # TODO: release GPU cluster submit scripts based on submitit for multi-node training\n","\n","    @classmethod\n","    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n","        \"\"\"\n","        Create evaluator(s) for a given dataset.\n","        This uses the special metadata \"evaluator_type\" associated with each\n","        builtin dataset. For your own dataset, you can simply create an\n","        evaluator manually in your script and do not have to worry about the\n","        hacky if-else logic here.\n","        \"\"\"\n","        if output_folder is None:\n","            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n","        evaluator_list = []\n","        evaluator_type = MetadataCatalog.get(dataset_name).evaluator_type\n","        # semantic segmentation\n","        if evaluator_type in [\"sem_seg\", \"ade20k_panoptic_seg\"]:\n","            evaluator_list.append(\n","                SemSegEvaluator(\n","                    dataset_name,\n","                    distributed=True,\n","                    output_dir=output_folder,\n","                )\n","            )\n","        # instance segmentation\n","        if evaluator_type == \"coco\":\n","            evaluator_list.append(COCOEvaluator(dataset_name, output_dir=output_folder))\n","        # panoptic segmentation\n","        if evaluator_type in [\n","            \"coco_panoptic_seg\",\n","            \"ade20k_panoptic_seg\",\n","            \"cityscapes_panoptic_seg\",\n","            \"mapillary_vistas_panoptic_seg\",\n","        ]:\n","            if cfg.MODEL.MaskDINO.TEST.PANOPTIC_ON:\n","                evaluator_list.append(COCOPanopticEvaluator(dataset_name, output_folder))\n","        # COCO\n","        if evaluator_type == \"coco_panoptic_seg\" and cfg.MODEL.MaskDINO.TEST.INSTANCE_ON:\n","            evaluator_list.append(COCOEvaluator(dataset_name, output_dir=output_folder))\n","        if evaluator_type == \"coco_panoptic_seg\" and cfg.MODEL.MaskDINO.TEST.SEMANTIC_ON:\n","            evaluator_list.append(SemSegEvaluator(dataset_name, distributed=True, output_dir=output_folder))\n","        # Mapillary Vistas\n","        if evaluator_type == \"mapillary_vistas_panoptic_seg\" and cfg.MODEL.MaskDINO.TEST.INSTANCE_ON:\n","            evaluator_list.append(InstanceSegEvaluator(dataset_name, output_dir=output_folder))\n","        if evaluator_type == \"mapillary_vistas_panoptic_seg\" and cfg.MODEL.MaskDINO.TEST.SEMANTIC_ON:\n","            evaluator_list.append(SemSegEvaluator(dataset_name, distributed=True, output_dir=output_folder))\n","        # Cityscapes\n","        if evaluator_type == \"cityscapes_instance\":\n","            assert (\n","                torch.cuda.device_count() > comm.get_rank()\n","            ), \"CityscapesEvaluator currently do not work with multiple machines.\"\n","            return CityscapesInstanceEvaluator(dataset_name)\n","        if evaluator_type == \"cityscapes_sem_seg\":\n","            assert (\n","                torch.cuda.device_count() > comm.get_rank()\n","            ), \"CityscapesEvaluator currently do not work with multiple machines.\"\n","            return CityscapesSemSegEvaluator(dataset_name)\n","        if evaluator_type == \"cityscapes_panoptic_seg\":\n","            if cfg.MODEL.MaskDINO.TEST.SEMANTIC_ON:\n","                assert (\n","                    torch.cuda.device_count() > comm.get_rank()\n","                ), \"CityscapesEvaluator currently do not work with multiple machines.\"\n","                evaluator_list.append(CityscapesSemSegEvaluator(dataset_name))\n","            if cfg.MODEL.MaskDINO.TEST.INSTANCE_ON:\n","                assert (\n","                    torch.cuda.device_count() > comm.get_rank()\n","                ), \"CityscapesEvaluator currently do not work with multiple machines.\"\n","                evaluator_list.append(CityscapesInstanceEvaluator(dataset_name))\n","        # ADE20K\n","        if evaluator_type == \"ade20k_panoptic_seg\" and cfg.MODEL.MaskDINO.TEST.INSTANCE_ON:\n","            evaluator_list.append(InstanceSegEvaluator(dataset_name, output_dir=output_folder))\n","        # LVIS\n","        if evaluator_type == \"lvis\":\n","            return LVISEvaluator(dataset_name, output_dir=output_folder)\n","        if len(evaluator_list) == 0:\n","            raise NotImplementedError(\n","                \"no Evaluator for the dataset {} with the type {}\".format(\n","                    dataset_name, evaluator_type\n","                )\n","            )\n","        elif len(evaluator_list) == 1:\n","            return evaluator_list[0]\n","        return DatasetEvaluators(evaluator_list)\n","\n","    @classmethod\n","    def build_train_loader(cls, cfg):\n","        # coco instance segmentation lsj new baseline\n","        if cfg.INPUT.DATASET_MAPPER_NAME == \"coco_instance_lsj\":\n","            mapper = COCOInstanceNewBaselineDatasetMapper(cfg, True)\n","            return build_detection_train_loader(cfg, mapper=mapper)\n","        # coco instance segmentation lsj new baseline\n","        elif cfg.INPUT.DATASET_MAPPER_NAME == \"coco_instance_detr\":\n","            mapper = DetrDatasetMapper(cfg, True)\n","            return build_detection_train_loader(cfg, mapper=mapper)\n","        # coco panoptic segmentation lsj new baseline\n","        elif cfg.INPUT.DATASET_MAPPER_NAME == \"coco_panoptic_lsj\":\n","            mapper = COCOPanopticNewBaselineDatasetMapper(cfg, True)\n","            return build_detection_train_loader(cfg, mapper=mapper)\n","        # Semantic segmentation dataset mapper\n","        elif cfg.INPUT.DATASET_MAPPER_NAME == \"mask_former_semantic\":\n","            mapper = MaskFormerSemanticDatasetMapper(cfg, True)\n","            return build_detection_train_loader(cfg, mapper=mapper)\n","        else:\n","            mapper = None\n","            return build_detection_train_loader(cfg, mapper=mapper)\n","\n","    @classmethod\n","    def build_lr_scheduler(cls, cfg, optimizer):\n","        \"\"\"\n","        It now calls :func:`detectron2.solver.build_lr_scheduler`.\n","        Overwrite it if you'd like a different scheduler.\n","        \"\"\"\n","        return build_lr_scheduler(cfg, optimizer)\n","\n","    @classmethod\n","    def build_optimizer(cls, cfg, model):\n","        weight_decay_norm = cfg.SOLVER.WEIGHT_DECAY_NORM\n","        weight_decay_embed = cfg.SOLVER.WEIGHT_DECAY_EMBED\n","\n","        defaults = {}\n","        defaults[\"lr\"] = cfg.SOLVER.BASE_LR\n","        defaults[\"weight_decay\"] = cfg.SOLVER.WEIGHT_DECAY\n","\n","        norm_module_types = (\n","            torch.nn.BatchNorm1d,\n","            torch.nn.BatchNorm2d,\n","            torch.nn.BatchNorm3d,\n","            torch.nn.SyncBatchNorm,\n","            # NaiveSyncBatchNorm inherits from BatchNorm2d\n","            torch.nn.GroupNorm,\n","            torch.nn.InstanceNorm1d,\n","            torch.nn.InstanceNorm2d,\n","            torch.nn.InstanceNorm3d,\n","            torch.nn.LayerNorm,\n","            torch.nn.LocalResponseNorm,\n","        )\n","\n","        params: List[Dict[str, Any]] = []\n","        memo: Set[torch.nn.parameter.Parameter] = set()\n","        for module_name, module in model.named_modules():\n","            for module_param_name, value in module.named_parameters(recurse=False):\n","                if not value.requires_grad:\n","                    continue\n","                # Avoid duplicating parameters\n","                if value in memo:\n","                    continue\n","                memo.add(value)\n","\n","                hyperparams = copy.copy(defaults)\n","                if \"backbone\" in module_name:\n","                    hyperparams[\"lr\"] = hyperparams[\"lr\"] * cfg.SOLVER.BACKBONE_MULTIPLIER\n","                if (\n","                    \"relative_position_bias_table\" in module_param_name\n","                    or \"absolute_pos_embed\" in module_param_name\n","                ):\n","                    print(module_param_name)\n","                    hyperparams[\"weight_decay\"] = 0.0\n","                if isinstance(module, norm_module_types):\n","                    hyperparams[\"weight_decay\"] = weight_decay_norm\n","                if isinstance(module, torch.nn.Embedding):\n","                    hyperparams[\"weight_decay\"] = weight_decay_embed\n","                params.append({\"params\": [value], **hyperparams})\n","\n","        def maybe_add_full_model_gradient_clipping(optim):\n","            # detectron2 doesn't have full model gradient clipping now\n","            clip_norm_val = cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE\n","            enable = (\n","                cfg.SOLVER.CLIP_GRADIENTS.ENABLED\n","                and cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE == \"full_model\"\n","                and clip_norm_val > 0.0\n","            )\n","\n","            class FullModelGradientClippingOptimizer(optim):\n","                def step(self, closure=None):\n","                    all_params = itertools.chain(*[x[\"params\"] for x in self.param_groups])\n","                    torch.nn.utils.clip_grad_norm_(all_params, clip_norm_val)\n","                    super().step(closure=closure)\n","\n","            return FullModelGradientClippingOptimizer if enable else optim\n","\n","        optimizer_type = cfg.SOLVER.OPTIMIZER\n","        if optimizer_type == \"SGD\":\n","            optimizer = maybe_add_full_model_gradient_clipping(torch.optim.SGD)(\n","                params, cfg.SOLVER.BASE_LR, momentum=cfg.SOLVER.MOMENTUM\n","            )\n","        elif optimizer_type == \"ADAMW\":\n","            optimizer = maybe_add_full_model_gradient_clipping(torch.optim.AdamW)(\n","                params, cfg.SOLVER.BASE_LR\n","            )\n","        else:\n","            raise NotImplementedError(f\"no optimizer type {optimizer_type}\")\n","        if not cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE == \"full_model\":\n","            optimizer = maybe_add_gradient_clipping(cfg, optimizer)\n","        return optimizer\n","\n","    @classmethod\n","    def test_with_TTA(cls, cfg, model):\n","        logger = logging.getLogger(\"detectron2.trainer\")\n","        # In the end of training, run an evaluation with TTA.\n","        logger.info(\"Running inference with test-time augmentation ...\")\n","        model = SemanticSegmentorWithTTA(cfg, model)\n","        evaluators = [\n","            cls.build_evaluator(\n","                cfg, name, output_folder=os.path.join(cfg.OUTPUT_DIR, \"inference_TTA\")\n","            )\n","            for name in cfg.DATASETS.TEST\n","        ]\n","        res = cls.test(cfg, model, evaluators)\n","        res = OrderedDict({k + \"_TTA\": v for k, v in res.items()})\n","        return res\n","\n","\n","def setup(args):\n","    \"\"\"\n","    Create configs and perform basic setups.\n","    \"\"\"\n","    cfg = get_cfg()\n","    # for poly lr schedule\n","    add_deeplab_config(cfg)\n","    add_maskdino_config(cfg)\n","    cfg.merge_from_file(args.config_file)\n","    cfg.merge_from_list(args.opts)\n","    cfg.freeze()\n","    default_setup(cfg, args)\n","    setup_logger(output=cfg.OUTPUT_DIR, distributed_rank=comm.get_rank(), name=\"maskdino\")\n","    return cfg\n","\n","\n","def main(args):\n","    cfg = setup(args)\n","    print(\"Command cfg:\", cfg)\n","    if args.eval_only:\n","        model = Trainer.build_model(cfg)\n","        DetectionCheckpointer(model, save_dir=cfg.OUTPUT_DIR).resume_or_load(\n","            cfg.MODEL.WEIGHTS, resume=args.resume\n","        )\n","        checkpointer = DetectionCheckpointer(model, save_dir=cfg.OUTPUT_DIR)\n","        checkpointer.resume_or_load(\n","            cfg.MODEL.WEIGHTS, resume=args.resume\n","        )\n","        res = Trainer.test(cfg, model)\n","        if cfg.TEST.AUG.ENABLED:\n","            res.update(Trainer.test_with_TTA(cfg, model))\n","        if comm.is_main_process():\n","            verify_results(cfg, res)\n","        return res\n","\n","    # register datasets\n","    register_coco_instances(\"ttpla_train\", {}, \"/kaggle/input/ttpla-project-dataset/ttpla/training_set/train.json\", \"/kaggle/input/ttpla-project-dataset/ttpla/training_set\")\n","    register_coco_instances(\"ttpla_test\", {}, \"/kaggle/input/ttpla-project-dataset/ttpla/test_set/test.json\", \"/kaggle/input/ttpla-project-dataset/ttpla/test_set\")\n","    convert_to_coco_json(\"ttpla_train\", \"/kaggle/working/train.json\", allow_cached=False)\n","    convert_to_coco_json(\"ttpla_test\", \"/kaggle/working/test.json\", allow_cached=False)\n","    trainer = Trainer(cfg)\n","    trainer.resume_or_load(resume=args.resume)\n","    return trainer.train()\n","\n","\n","if __name__ == \"__main__\":\n","    parser = default_argument_parser()\n","    parser.add_argument('--eval_only', action='store_true')\n","    parser.add_argument('--EVAL_FLAG', type=int, default=1)\n","    args = parser.parse_args()\n","    # random port\n","    port = random.randint(1000, 20000)\n","    args.dist_url = 'tcp://127.0.0.1:' + str(port)\n","    print(\"Command Line Args:\", args)\n","    print(\"pwd:\", os.getcwd())\n","    launch(\n","        main,\n","        args.num_gpus,\n","        num_machines=args.num_machines,\n","        machine_rank=args.machine_rank,\n","        dist_url=args.dist_url,\n","        args=(args,),\n","    )''')\n","file.close()"]},{"cell_type":"markdown","metadata":{},"source":["----- Training del modello -------"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T22:54:27.395980Z","iopub.status.busy":"2024-01-14T22:54:27.395025Z","iopub.status.idle":"2024-01-14T22:58:43.111792Z","shell.execute_reply":"2024-01-14T22:58:43.110618Z","shell.execute_reply.started":"2024-01-14T22:54:27.395944Z"},"trusted":true},"outputs":[],"source":["!python code/train_net.py --num-gpus 1 --config-file code/configs/coco/instance-segmentation/maskdino_R50_bs16_50ep_4s_dowsample1_2048.yaml MODEL.WEIGHTS /kaggle/input/maskdino-state-of-art/model_final.pth"]},{"cell_type":"markdown","metadata":{},"source":["---Recupero dei pesi del modello addestrato---"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-14T22:51:07.620618Z","iopub.status.idle":"2024-01-14T22:51:07.620948Z","shell.execute_reply":"2024-01-14T22:51:07.620800Z","shell.execute_reply.started":"2024-01-14T22:51:07.620784Z"},"trusted":true},"outputs":[],"source":["from IPython.display import FileLink \n","\n","FileLink(r'checkpoint/model_final.pth')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4118714,"sourceId":7137341,"sourceType":"datasetVersion"},{"datasetId":4130445,"sourceId":7153195,"sourceType":"datasetVersion"},{"datasetId":4135934,"sourceId":7160856,"sourceType":"datasetVersion"},{"datasetId":4148926,"sourceId":7178750,"sourceType":"datasetVersion"},{"datasetId":4232297,"sourceId":7296493,"sourceType":"datasetVersion"},{"datasetId":4302534,"sourceId":7399594,"sourceType":"datasetVersion"},{"datasetId":4303682,"sourceId":7401246,"sourceType":"datasetVersion"},{"datasetId":4304631,"sourceId":7402583,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
